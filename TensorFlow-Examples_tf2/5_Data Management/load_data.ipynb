{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load and parse data with TensorFlow 2.0 (tf.data)\n",
    "\n",
    "A TensorFlow 2.0 example to build input pipelines for loading data efficiently.\n",
    "\n",
    "- Numpy Arrays\n",
    "- Images\n",
    "- CSV file\n",
    "- Custom data from a Generator\n",
    "\n",
    "For more information about creating and loading TensorFlow's TFRecords data format, see: tfrecords.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import requests\n",
    "import string\n",
    "import tarfile\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Numpy Arrays\n",
    "\n",
    "Build a data pipeline over numpy arrays."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Create a toy dataset (even and odd numbers, with respective labels of 0 and 1).\n",
    "evens = np.arange(0, 100, step=2, dtype=np.int32)\n",
    "evens_label = np.zeros(50, dtype=np.int32)\n",
    "odds = np.arange(1, 100, step=2, dtype=np.int32)\n",
    "odds_label = np.ones(50, dtype=np.int32)\n",
    "# Concatenate arrays\n",
    "features = np.concatenate([evens, odds])\n",
    "labels = np.concatenate([evens_label, odds_label])\n",
    "\n",
    "# Load a numpy array using tf data api with `from_tensor_slices`.\n",
    "data = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "# Refill data indefinitely.\n",
    "data = data.repeat()\n",
    "# Shuffle data.\n",
    "data = data.shuffle(buffer_size=100)\n",
    "# Batch data (aggregate records together).\n",
    "data = data.batch(batch_size=4)\n",
    "# Prefetch batch (pre-load batch for faster consumption).\n",
    "data = data.prefetch(buffer_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([77 54 37 78], shape=(4,), dtype=int32) tf.Tensor([1 0 1 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([10 40 52 15], shape=(4,), dtype=int32) tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([91 63 16 21], shape=(4,), dtype=int32) tf.Tensor([1 1 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([ 2 25 72  0], shape=(4,), dtype=int32) tf.Tensor([0 1 0 0], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for batch_x, batch_y in data.take(4):\n",
    "    print(batch_x, batch_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([44 13 24 85], shape=(4,), dtype=int32) tf.Tensor([0 1 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([15 49 98 52], shape=(4,), dtype=int32) tf.Tensor([1 1 0 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([95  6 89 14], shape=(4,), dtype=int32) tf.Tensor([1 0 1 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([10 67 12  8], shape=(4,), dtype=int32) tf.Tensor([0 1 0 0], shape=(4,), dtype=int32)\n",
      "tf.Tensor([94 10 76  1], shape=(4,), dtype=int32) tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([19 81 91  7], shape=(4,), dtype=int32) tf.Tensor([1 1 1 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([43 93 48 29], shape=(4,), dtype=int32) tf.Tensor([1 1 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([68 80 90 63], shape=(4,), dtype=int32) tf.Tensor([0 0 0 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([51 56 35 99], shape=(4,), dtype=int32) tf.Tensor([1 0 1 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([71 18 55 64], shape=(4,), dtype=int32) tf.Tensor([1 0 1 0], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Note: If you are planning on calling multiple time,\n",
    "# you can user the iterator way:\n",
    "ite_data = iter(data)\n",
    "for i in range(5):\n",
    "    batch_x, batch_y = next(ite_data)\n",
    "    print(batch_x, batch_y)\n",
    "\n",
    "for i in range(5):\n",
    "    batch_x, batch_y = next(ite_data)\n",
    "    print(batch_x, batch_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load CSV files\n",
    "\n",
    "Build a data pipeline from features stored in a CSV file. For this example, Titanic dataset will be used as a toy dataset stored in CSV format."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "# Download Titanic dataset (in csv format).\n",
    "d = requests.get(\"https://raw.githubusercontent.com/tflearn/tflearn.github.io/master/resources/titanic_dataset.csv\")\n",
    "with open(\"titanic_dataset.csv\", \"wb\") as f:\n",
    "    f.write(d.content)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "\n",
    "# Load Titanic dataset.\n",
    "# Original features: survived,pclass,name,sex,age,sibsp,parch,ticket,fare\n",
    "# Select specific columns: survived,pclass,name,sex,age,fare\n",
    "column_to_use = [0, 1, 2, 3, 4, 8]\n",
    "record_defaults = [tf.int32, tf.int32, tf.string, tf.string, tf.float32, tf.float32]\n",
    "\n",
    "# Load the whole dataset file, and slice each line.\n",
    "data = tf.data.experimental.CsvDataset(\"titanic_dataset.csv\", record_defaults, header=True, select_cols=column_to_use)\n",
    "# Refill data indefinitely.\n",
    "data = data.repeat()\n",
    "# Shuffle data.\n",
    "data = data.shuffle(buffer_size=1000)\n",
    "# Batch data (aggregate records together).\n",
    "data = data.batch(batch_size=2)\n",
    "# Prefetch batch (pre-load batch for faster consumption).\n",
    "data = data.prefetch(buffer_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[2 3]\n",
      "[b'Herman, Mrs. Samuel (Jane Laver)' b'Ilmakangas, Miss. Ida Livija']\n",
      "[b'female' b'female']\n",
      "[48. 27.]\n",
      "[65.     7.925]\n"
     ]
    }
   ],
   "source": [
    "for survived, pclass, name, sex, age, fare in data.take(1):\n",
    "    print(survived.numpy())\n",
    "    print(pclass.numpy())\n",
    "    print(name.numpy())\n",
    "    print(sex.numpy())\n",
    "    print(age.numpy())\n",
    "    print(fare.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Images\n",
    "\n",
    "Build a data pipeline by loading images from disk. For this example, Oxford Flowers dataset will be used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Download Oxford 17 flowers dataset\n",
    "d = requests.get(\"http://www.robots.ox.ac.uk/~vgg/data/flowers/17/17flowers.tgz\")\n",
    "with open(\"17flowers.tgz\", \"wb\") as f:\n",
    "    f.write(d.content)\n",
    "# Extract archive.\n",
    "with tarfile.open(\"17flowers.tgz\") as t:\n",
    "    t.extractall()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "with open('jpg/dataset.csv', 'w') as f:\n",
    "    c = 0\n",
    "    for i in range(1360):\n",
    "        f.write(\"jpg/image_%04i.jpg,%i\\n\" % (i+1, c))\n",
    "        if (i+1) % 80 == 0:\n",
    "            c += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "\n",
    "# Load Images\n",
    "with open(\"jpg/dataset.csv\") as f:\n",
    "    dataset_file = f.read().splitlines()\n",
    "\n",
    "# Load the whole dataset file, and slice each line.\n",
    "data = tf.data.Dataset.from_tensor_slices(dataset_file)\n",
    "# Refill data indefinitely.\n",
    "data = data.repeat()\n",
    "# Shuffle data.\n",
    "data = data.shuffle(buffer_size=1000)\n",
    "\n",
    "# Load and pre-process images.\n",
    "def load_image(path):\n",
    "    # Read image from path.\n",
    "    image = tf.io.read_file(path)\n",
    "    # Decode the jpeg image to array [0, 255].\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    # Resize images to a common size of 256x256.\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    # Rescale values to [-1, 1].\n",
    "    image = 1. - image / 127.5\n",
    "    return image\n",
    "# Decode each line from the dataset file.\n",
    "def parse_records(line):\n",
    "    # File is in csv format: \"image_path,label_id\".\n",
    "    # TensorFlow requires a default value, but it will never be used.\n",
    "    image_path, image_label = tf.io.decode_csv(line, [\"\", 0])\n",
    "    # Apply the function to load images.\n",
    "    image = load_image(image_path)\n",
    "    return image, image_label\n",
    "# Use 'map' to apply the above functions in parallel.\n",
    "data = data.map(parse_records, num_parallel_calls=4)\n",
    "\n",
    "# Batch data (aggregate images-array together).\n",
    "data = data.batch(batch_size=2)\n",
    "# Prefetch batch (pre-load batch for faster consumption).\n",
    "data = data.prefetch(buffer_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0.34748775  0.06513482  0.34748775]\n",
      "   [ 0.35533088  0.06960785  0.37775737]\n",
      "   [ 0.34448528  0.0699755   0.3897059 ]\n",
      "   ...\n",
      "   [ 0.4196691   0.25496322  0.58621323]\n",
      "   [ 0.45851713  0.27028185  0.65569854]\n",
      "   [ 0.47053224  0.28229696  0.6744538 ]]\n",
      "\n",
      "  [[ 0.38229167  0.09344363  0.37904412]\n",
      "   [ 0.39350492  0.10268217  0.41268384]\n",
      "   [ 0.39213914  0.11362064  0.43535537]\n",
      "   ...\n",
      "   [ 0.36305147  0.1983456   0.5295956 ]\n",
      "   [ 0.39405638  0.2058211   0.5912378 ]\n",
      "   [ 0.409375    0.22113973  0.61329657]]\n",
      "\n",
      "  [[ 0.4353817   0.12165624  0.4118523 ]\n",
      "   [ 0.43884802  0.14080882  0.45343137]\n",
      "   [ 0.44332105  0.15312499  0.48069853]\n",
      "   ...\n",
      "   [ 0.36481935  0.1844272   0.5392066 ]\n",
      "   [ 0.3849442   0.19670892  0.58212554]\n",
      "   [ 0.4001838   0.21194851  0.60410535]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.55012256  0.61286765  0.71482843]\n",
      "   [ 0.41425925  0.47700435  0.5789651 ]\n",
      "   [ 0.37647057  0.43137252  0.5568627 ]\n",
      "   ...\n",
      "   [ 0.18499684  0.20852625  0.25374687]\n",
      "   [ 0.13633579  0.16770834  0.16660541]\n",
      "   [ 0.1481005   0.17947304  0.1716299 ]]\n",
      "\n",
      "  [[ 0.6749507   0.7376958   0.8396566 ]\n",
      "   [ 0.5944853   0.6572304   0.75919116]\n",
      "   [ 0.57412446  0.6290264   0.7545166 ]\n",
      "   ...\n",
      "   [ 0.22020286  0.24373227  0.2889529 ]\n",
      "   [ 0.21825981  0.24963236  0.24852943]\n",
      "   [ 0.23393029  0.26530284  0.2574597 ]]\n",
      "\n",
      "  [[ 0.7771446   0.8398897   0.9418505 ]\n",
      "   [ 0.7371936   0.79993874  0.9018995 ]\n",
      "   [ 0.73131126  0.7862132   0.9117034 ]\n",
      "   ...\n",
      "   [ 0.24822307  0.27175248  0.31697303]\n",
      "   [ 0.20631129  0.23768383  0.23658091]\n",
      "   [ 0.21825981  0.24963236  0.24178922]]]\n",
      "\n",
      "\n",
      " [[[-0.06623161 -0.35682595  0.01271755]\n",
      "   [ 0.09454048 -0.18346202  0.20973653]\n",
      "   [ 0.09761029 -0.16579366  0.25349265]\n",
      "   ...\n",
      "   [-0.26007962 -0.42058825  0.00603569]\n",
      "   [-0.20856011 -0.3423438   0.10128665]\n",
      "   [-0.2897793  -0.39492345  0.07731616]]\n",
      "\n",
      "  [[-0.12353563 -0.3657385   0.00621319]\n",
      "   [ 0.07780331 -0.15988052  0.23413914]\n",
      "   [ 0.11162686 -0.10840964  0.31844383]\n",
      "   ...\n",
      "   [-0.31577802 -0.48417544 -0.06464434]\n",
      "   [-0.27439034 -0.41437197  0.0170005 ]\n",
      "   [-0.26613665 -0.38622236  0.06010115]]\n",
      "\n",
      "  [[-0.03969085 -0.20053637  0.18079025]\n",
      "   [ 0.01092166 -0.15419781  0.2509492 ]\n",
      "   [ 0.06950063 -0.10009193  0.34126848]\n",
      "   ...\n",
      "   [-0.29977024 -0.5020375  -0.06965351]\n",
      "   [-0.30623436 -0.46943915 -0.05770504]\n",
      "   [-0.28434432 -0.41839767 -0.01380205]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.07742035 -0.24215686  0.5252605 ]\n",
      "   [ 0.07397377 -0.2384038   0.49663   ]\n",
      "   [ 0.07221234 -0.23134148  0.44413328]\n",
      "   ...\n",
      "   [-0.04603243 -0.33273602  0.45877784]\n",
      "   [-0.03872514 -0.33383846  0.5123168 ]\n",
      "   [-0.0352788  -0.33823526  0.5579351 ]]\n",
      "\n",
      "  [[ 0.10327506 -0.21045041  0.54581493]\n",
      "   [ 0.09342223 -0.21800554  0.4906311 ]\n",
      "   [-0.0085783  -0.31023276  0.32532167]\n",
      "   ...\n",
      "   [-0.04004276 -0.35615802  0.58040756]\n",
      "   [-0.02428317 -0.34372246  0.6096872 ]\n",
      "   [-0.0185324  -0.34129596  0.6336428 ]]\n",
      "\n",
      "  [[ 0.07669115 -0.2321477   0.50613356]\n",
      "   [ 0.0725981  -0.24215376  0.45214772]\n",
      "   [-0.12578118 -0.42562795  0.17287081]\n",
      "   ...\n",
      "   [-0.01269913 -0.349954    0.6913756 ]\n",
      "   [-0.00096822 -0.3371967   0.70080876]\n",
      "   [-0.00685668 -0.33626842  0.6617402 ]]]], shape=(2, 256, 256, 3), dtype=float32) tf.Tensor([7 5], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for batch_x, batch_y in data.take(1):\n",
    "    print(batch_x, batch_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data from a Generator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# Create a dummy generator.\n",
    "def generate_features():\n",
    "    # Function to generate a random string.\n",
    "    def random_string(length):\n",
    "        return ''.join(random.choice(string.ascii_letters) for m in range(length))\n",
    "    # Return a random string, a random vector, and a random int.\n",
    "    yield random_string(4), np.random.uniform(size=4), random.randint(0, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "\n",
    "# Load a numpy array using tf data api with `from_tensor_slices`.\n",
    "data = tf.data.Dataset.from_generator(generate_features, output_types=(tf.string, tf.float32, tf.int32))\n",
    "# Refill data indefinitely.\n",
    "data = data.repeat()\n",
    "# Shuffle data.\n",
    "data = data.shuffle(buffer_size=100)\n",
    "# Batch data (aggregate records together).\n",
    "data = data.batch(batch_size=4)\n",
    "# Prefetch batch (pre-load batch for faster consumption).\n",
    "data = data.prefetch(buffer_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'nAHY' b'Coyh' b'uxwg' b'Nsby'], shape=(4,), dtype=string) tf.Tensor(\n",
      "[[0.2489901  0.5929806  0.8466293  0.3830717 ]\n",
      " [0.93540996 0.13090135 0.65848845 0.80020654]\n",
      " [0.44918388 0.57991904 0.87788606 0.7736005 ]\n",
      " [0.39685148 0.6460428  0.18117687 0.85636437]], shape=(4, 4), dtype=float32) tf.Tensor([1 8 7 7], shape=(4,), dtype=int32)\n",
      "tf.Tensor([b'tjRB' b'aVQy' b'wxwy' b'Mjvq'], shape=(4,), dtype=string) tf.Tensor(\n",
      "[[0.3744202  0.84489506 0.13605866 0.8272498 ]\n",
      " [0.14347935 0.39562988 0.04686269 0.40373808]\n",
      " [0.25841206 0.18076964 0.9293564  0.96094453]\n",
      " [0.73246574 0.22075218 0.5999108  0.8323621 ]], shape=(4, 4), dtype=float32) tf.Tensor([1 1 9 6], shape=(4,), dtype=int32)\n",
      "tf.Tensor([b'LNhW' b'jPsY' b'ZZOj' b'QcyK'], shape=(4,), dtype=string) tf.Tensor(\n",
      "[[0.42397648 0.96731174 0.3776846  0.5525027 ]\n",
      " [0.66115    0.38694072 0.289318   0.09513511]\n",
      " [0.22792904 0.7793351  0.40683118 0.8259607 ]\n",
      " [0.317663   0.2975126  0.41752937 0.973576  ]], shape=(4, 4), dtype=float32) tf.Tensor([ 9  9 10  4], shape=(4,), dtype=int32)\n",
      "tf.Tensor([b'WWfl' b'ohhx' b'VzTn' b'yUEa'], shape=(4,), dtype=string) tf.Tensor(\n",
      "[[0.6793589  0.05437504 0.37608704 0.8314346 ]\n",
      " [0.7543086  0.2922054  0.32019588 0.89579135]\n",
      " [0.56507385 0.6899922  0.49918616 0.02968103]\n",
      " [0.20877157 0.44584292 0.24360909 0.85562307]], shape=(4, 4), dtype=float32) tf.Tensor([10  6  2  8], shape=(4,), dtype=int32)\n",
      "tf.Tensor([b'jnQF' b'GbKq' b'iljf' b'RVEq'], shape=(4,), dtype=string) tf.Tensor(\n",
      "[[0.17159824 0.16089246 0.6573498  0.35442865]\n",
      " [0.51204365 0.00131886 0.09008746 0.01222453]\n",
      " [0.9103229  0.6243061  0.563899   0.38998967]\n",
      " [0.03070712 0.23799402 0.44242215 0.08821636]], shape=(4, 4), dtype=float32) tf.Tensor([ 3 10  9  1], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display data.\n",
    "for batch_str, batch_vector, batch_int in data.take(5):\n",
    "    print(batch_str, batch_vector, batch_int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tf2_0_0",
   "language": "python",
   "display_name": "tf2_0_0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}